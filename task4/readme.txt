В board.jpg есть примерная схема.

Я поделил RED_STATS на 3 сервиса, каждый со своей базой.

От сервиса RED дополнительно потребуется посылать сообщения с (user_id, red_value) в exchange типа fanout в
rabbitmq. К этому эксченджу будет подключено 3 очереди, на которые будут подписаны red_stat_store, red_stat_subscribe
и red_stat_websocket.

Базы данных пусть будут, для начала, postgresql

1. red_stat_store - хранилище истории, из которого можно достать статистику по времени
В базе нужна будет таблица с колонками (user_id, red_value, when).
Сразу нужны индексы по (red_value, when) для статистики по времени.
И отдельно по (red_value), для статистики по изображениям "у которых красного было больше заданного значения"

Сам сервис - просто отвечает на http запросы от клиентов результатами селектов из базы.

На каждое новое сообщение из очереди - создает новую запись в базу.

2. red_stat_subscribe - подписка по электронной почте
В базе нужна будет таблица с колонками (user_id, red_threshold, email)
Индекс нужен по red_threshold.

Эндпоинт /sub принимает red_threshold и email и сохранчет их в базу.

Когда приходит сообщение из очереди - сервис ищет все строки в базе с red_threshold меньше red_value из сообщения,
и отправляет им всем письма.


3. red_stat_notify - оповещение через websocket
Если у сервиса RED_STATS есть веб приложение, то оно сможет поключится через вебсокет, сообщить свой red_threshold
и получать оповещения моментально.

На картинке у сервиса тоже нарисована база - но она не нужна, на самом деле.

Сервис для каждого открытого соединения, должен хранить red_threshold и, если из rabbitmq приходит сообщение
с red_value больше red_threshold - посылать в сокет сообщение. Т.к. если сервис перезапустится - соединения все равно
порвутся, кешировать их параметры где-то на стороне нет смысла.

Еще, на каждый запущеный экземпляр этого сервиса, нужна будет своя очередь в rabbitmq, подключенная к exchange,
рассылающему результаты сервиса работы RED. Таким образом, логика работы, в случае нескольких запущеных экземпляров
получается довольно простой - пришло сообщение из очереди, сравнили значение с red_threshold для открытых соединений,
послали сообщения, если результат больше порога.



Общение с пользователем:
3 эндпоинта: /stat, /sub, /ws По одному на каждый из микросервисов. Перед ними должен стоять балансировщик,
раскидывающий запросы и websocket коннекты по сервисам.



Масштабирование:
red_stat_store, red_stat_subscribe  получились полностью stateless, их можно запустить неограниченое количество.
Поэтому маштабирование нужно будет для баз данных и rabbitmq.

postgres - можно оптимировать разбив большие таблицы с историческими данными на партиции(по суткам или по часам).
И создать отдельные реплики для чтения и записи данных(т.е. запись - в master, чтение со slave)

rabbitmq - у меня мало опыта в его администрировании и масштабировании, конкретно ничего сказать не могу.
Но там тоже есть инструменты для кластеризации, я бы посмотрел сначала на них.

red_stat_notify - можно масштабировать просто запуская больше инстансов сервиса, пока не упремся в производительность
rabbitmq



Также я ничего не сказал про аутентификацию пользователей. Предполагаю, что в сервисе RED она уже существует
и ее можно переиспользовать. Ну или аутентификация вообще не нужна.